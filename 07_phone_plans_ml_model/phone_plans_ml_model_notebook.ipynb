{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de un modelo de Machine Learning para planes de telefonía"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenido"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#)\n",
    "* [Objetivos](#)\n",
    "* [Etapas](#)\n",
    "* [Inicialización: descripción de datos](#)\n",
    "    * [Cargar datos](#)\n",
    "* [Segmentación de datos](#)\n",
    "* [Prueba y entrenamiento de modelos de Machine Learning](#)\n",
    "* [Prueba de calidad del modelo](#)\n",
    "* [Prueba de cordura](#)\n",
    "* [Conclusiones](#)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compañía de telecomunicaciones móviles Megaline, viendo el análisis realizado previamente en el estudio de sus planes de telefonía, ahora nos propone un nuevo reto y análisis al ver que muchos de sus clientes utilizan planes heredados y que no siempre se ajustan a lo que ellos necesitan. Megaline quiere que desarrollemos un modelo de Machine Learning que pueda analizar el comportamiento de sus clientes y (pronosticar) recomendar uno de los planes de la empresa: Smart o Ultra. Para el desarrollo de este proyecto utilizaremos modelos de aprendizaje automático supervisados, en este caso, los de clasificación.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Debido a que nuestro objetivo es el modelamiento, no tenemos hipótesis estadísticas a probar en específico esta vez.* \n",
    "\n",
    "Nuestro principal objetivo será determinar el modelo con la mayor exactitud posible, teniendo como umbral de exactitud un 0.75.\n",
    "\n",
    "Como tarea adicional, probaremos la calidad del modelo y realizaremos una prueba de cordura."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapas del análisis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto, seguiremos un esquema necesario para solucionar el problema de la creación y prueba de un modelo de Machine Learning. Para esto, seguiremos a grandes rasgos el siguiente proceso:\n",
    "\n",
    "1. Descripción de los datos\n",
    "2. Segmentación de los datos\n",
    "3. Prueba y entrenamiento de los modelos de Machine Learning\n",
    "4. Prueba de calidad del modelo\n",
    "5. Prueba de cordura\n",
    "6. Conclusiones finales\n",
    "\n",
    "Debido a que el preprocesamiento y análisis exploratorio fueron realizados en el anterior informe, en este presente trabajo se obviarán esos pasos y nos enfocaremos en el modelamiento luego de describir nuestros datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización: descripción de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga de librerías necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd # librerías estándar para manipular datos\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression  # librerías de sklearn para los modelos y métricas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos solo un dataset con los datos finales y preprocesados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_megaline = pd.read_csv(\"users_behavior.csv\")\n",
    "except:\n",
    "    data_megaline = pd.read_csv(\"datasets/users_behavior.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración inicial de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra tabla contiene la siguiente información según su documentación:\n",
    "\n",
    "* ``calls``: número de llamadas.\n",
    "* ``minutes``: duración total de la llamada en minutos.\n",
    "* ``messages``: número de mensajes de texto.\n",
    "* ``mb_used``: tráfico de internet utilizado en MB.\n",
    "* ``is_ultra``: si el plan utilizado es el *Ultra* (1), de lo contrario, es Smart (0)\n",
    "\n",
    "Ahora podemos explorar la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_megaline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_megaline.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "data_megaline.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo mostrado previamente, podemos notar que ninguna de nuestra variables cuenta con problemas grandes en su distribución, tipos de datos y valores ausentes. El motivo es precisamente el hecho de que el preprocesamiento ya fue realizado en el anterior trabajo. \n",
    "\n",
    "Ahora que conocemos a nuestras variables y sabemos que estas no presentan problemas para su uso, nos enfocaremos en nuestra posible variable objetivo: ``is_ultra``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.693528\n",
       "1    0.306472\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_megaline['is_ultra'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 30 % de los usuarios tienen registrado el plan *Ultra* en su suscripción a la empresa Megaline, mientras que el 70 % restante pertenece al plan *Smart*. Esta diferencia muestra y sugiere la existencia de un ligero desbalance de nuestra variable objetivo. Debido a que el problema no se ve lo suficientemente grave como para preocuparnos por él, no se abordará el manejo de este problema por ahora y esa será la limitación de este proyecto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones del apartado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado observamos las principales características y dimos un vistazo general a nuestras variables. No notamos problemas que requieran una etapa de procesado extra debido a que este proceso fue realizado en el trabajo previo. También notamos un ligero desbalance en nuestra variable objetivo, pero se concluyó que su proporción no es grave ni posiblemente genere problemas en la estimación y evaluación de nuestro modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentación de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que realizaremos un modelo de clasificación predictivo, tendremos que definir una especie de relación de nuestra variable objetivo (target) a pronosticar y sus características (features). Ya habíamos anticipado este problema designando a ``is_ultra`` como nuestra variable objetivo, pero continuaremos buscando la relación en un modelo teórico no formal: \n",
    "\n",
    "Nuestra variable objetivo (``is_ultra``) teóricamente se relaciona con las variables ``calls``, ``minutes``, ``messages``, y ``mb_used`` (características). Es decir, existe una relación teórica no formal en la que esas características determinarán si el cliente usa un respectivo plan o no (variable objetivo - ``is_ultra``). En la vida real, esta relación tiene sentido y esa será la relación que nos ayude a generar nuestro modelo predictivo.\n",
    "\n",
    "Guardaremos nuestra semilla generadora de números pseudoaleatorios en la variable ``random_state``.\n",
    "\n",
    "A continuación, separaremos nuestro dataset en ``target`` y ``features``.\n",
    "\n",
    "Luego de lo anterior, necesitamos dividir nuestros datos para las respectivas etapas de entrenamiento y validación de nuestro modelo. Usaremos la función \"train_test_split\" para este objetivo, y emplearemos la proporción 3:1:1 al dividir los datos (60 % para entrenamiento, 20 % para validación y 20 % para la prueba final de calidad):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_megaline['is_ultra']\n",
    "features = data_megaline.drop('is_ultra', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero dividiremos y separaremos el conjunto de entrenamiento, dejando el 40 % de los datos para separarlos luego en los sets de validación y prueba (sets \"split\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train, target_split, features_train, features_split = train_test_split(target, features, test_size=0.40, random_state=random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora dividiremos los datasets \"split\" (que contienen al 40 % de los datos) en partes iguales que correspondan al dataset de validación y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_valid, target_test, features_valid, features_test = train_test_split(target_split, features_split, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificaremos obteniendo el atributo *shape* de cada dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo parece estar en orden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pequeñas conclusiones del apartado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado definimos la relación que nos permitirá la estimación del modelo, siendo ``is_ultra`` nuestra variable objetivo y las demás variables las características del modelo.\n",
    "\n",
    "Luego de definir estas variables, las separamos y, a continuación, dividimos nuestro dataset para el entrenamiento (75 %) y validación (25 %). Finalmente, nos aseguramos de que la división se haya realizado correctamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba y entrenamiento de los modelos de Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como nombrábamos líneas arriba, este trabajo se trata de uno de clasificación, para lo cual hemos cargado tres modelos de clasificación que usaremos para obtener el mejor modelo en términos de exactitud (*accuracy*) que probaremos en el orden mostrado:\n",
    "* Árbol de decisión (Decision Tree Classifier)\n",
    "* Bosque aleatorio (Random Forest Classifier)\n",
    "* Regresión logística, logit (Logistic Regression)\n",
    "\n",
    "En esta etapa, usaremos los datasets segmentados para entrenar y validar los mejores parámetros de nuestros modelos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión - Decision Tree Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El principal hiperparámetro de este modelo es la profundidad máxima (*max_depth*) y obtendremos su valor óptimo utilizando un bucle hasta un límite de 20. Para evitar el overfitting, compararemos *accuracy* y determinaremos como mejor modelo al que tenga el más alto valor de *accuracy* con el set de validación. De forma visual, tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La profundidad óptima del modelo es: 6\n",
      "Accuracy del modelo óptimo: 0.8055987558320373\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth_tree = 0\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    model_tree = DecisionTreeClassifier(max_depth=depth, random_state=random_state)\n",
    "    model_tree.fit(features_train, target_train)\n",
    "    \n",
    "    accuracy_tree = model_tree.score(features_valid, target_valid)\n",
    "    \n",
    "    if accuracy_tree > best_result:\n",
    "        best_result = accuracy_tree\n",
    "        best_depth_tree = depth\n",
    "\n",
    "print(f\"La profundidad óptima del modelo es: {best_depth_tree}\")\n",
    "print(f\"Accuracy del modelo óptimo: {best_result}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, el modelo que resulta con la mejor exactitud sin caer en el sobreajuste tiene una profundidad máxima de 6 y resulta cumplir con los requisitos del umbral mínimo de exactitud. Continuaremos probando con los demás modelos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bosque aleatorio - Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este modelo, usaremos la misma lógica del anterior, en el cual mediante un bucle buscaremos y determinaremos los mejores hiperparámetros y exactitud. En este caso, los hiperparámetros principales a buscar son la cantidad de árboles y su profundidad máxima, así que usaremos dos bucles limitando la cantidad de iteraciones para 50 árboles y 20 de profundidad máxima, de la manera siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La profundidad del modelo óptima es: 10\n",
      "El número de árboles óptimos del modelo es: 40\n",
      "Accuracy del modelo óptimo: 0.8195956454121306\n"
     ]
    }
   ],
   "source": [
    "best_n_forest = 0\n",
    "best_depth_forest = 0\n",
    "best_result_forest = 0\n",
    "\n",
    "for n in range(10, 51, 10):\n",
    "    for depth in range(1, 21):\n",
    "        model_forest = RandomForestClassifier(n_estimators=n, max_depth=depth, random_state=random_state)\n",
    "        model_forest.fit(features_train, target_train)\n",
    "        \n",
    "        accuracy_forest = model_forest.score(features_valid, target_valid)\n",
    "        \n",
    "        if accuracy_forest > best_result_forest:\n",
    "            best_n_forest = n\n",
    "            best_depth_forest = depth\n",
    "            best_result_forest = accuracy_forest\n",
    "\n",
    "print(f\"La profundidad del modelo óptima es: {best_depth_forest}\")\n",
    "print(f\"El número de árboles óptimos del modelo es: {best_n_forest}\")\n",
    "print(f\"Accuracy del modelo óptimo: {best_result_forest}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De estos resultados podemos concluir que, aparte de que el tiempo de entrenamiento es más largo, tenemos una mejor exactitud respecto al árbol de decisión. El hecho de que la pequeña diferencia en exactitud pueda compensar el tiempo de espera es algo a considerar al momento de utilizar este modelo. Por otro lado, la profundidad de los árboles que nos indica como óptima es de 10, y el número de árboles en 40. Por último, al introducir una relativa gran profundidad máxima, este modelo tiene más probabilidad de presentar sobreajuste respecto al anterior, aunque esperamos *a priori* que esto no sea un problema en este momento. Finalizaremos con el último modelo: regresión logística."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística - Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También usaremos un bucle de forma análoga a los modelos previos, pero el hiperparámetro más relevante en una regresión logística, desde el punto de vista del autor dada la naturaleza de los datos, resulta ser el método de resolución del problema de optimización de los parámetros del modelo: *solver*. Incluiremos los tipos de *solver* disponibles en una lista e iteraremos buscando aquel que de mejores resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\I3\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\I3\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor método 'solver' de la regresión logística es: newton-cholesky\n",
      "Accuracy del modelo óptimo: 0.744945567651633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\I3\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\I3\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    }
   ],
   "source": [
    "best_result_logistic = 0\n",
    "best_solver = None\n",
    "\n",
    "solver_list = ['liblinear', 'lbfgs', 'sag', 'newton-cholesky', 'saga', 'newton-cg']\n",
    "\n",
    "for method in solver_list:\n",
    "    model_logistic = LogisticRegression(solver=method, random_state=random_state)\n",
    "    model_logistic.fit(features_train, target_train)\n",
    "    \n",
    "    accuracy_logistic = model_logistic.score(features_valid, target_valid)\n",
    "    \n",
    "    if accuracy_logistic > best_result_logistic:\n",
    "        best_result_logistic = accuracy_logistic\n",
    "        best_solver = method\n",
    "        \n",
    "print(f\"El mejor método 'solver' de la regresión logística es: {best_solver}\")\n",
    "print(f\"Accuracy del modelo óptimo: {best_result_logistic}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este modelo, el hiperparámetro *solver* que nos recomienda este proceso es el de \"newton-cholesky\". Sin embargo, tenemos un problema porque este modelo no pasa el umbral mínimo que se requiere para continuar con su uso, aunque está muy próximo a él. Por este motivo, para el siguiente apartado prescindiremos de este modelo y nos enfocaremos en probar la calidad final con los dos restantes: *Decision Tree* y *Random Forest*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pequeñas conclusiones del apartado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de un proceso iterativo, logramos determinar los mejores hiperparámetros de los tres modelos. Aunque resultó que uno de ellos (Regresión logística) no logró pasar el umbral mínimo de exactitud requerido para continuar con el proceso. Los modelos finalistas son:\n",
    "* *Decision Tree*, con *max_depth* = 6. \n",
    "* *Random Forest*, con *max_depth* = 10 y *n_estimators* = 40."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de calidad del modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que depuramos y nos quedamos con dos modelos, ahora nos toca utilizar nuestro último dataset (el de test) para la prueba final del modelo y finalmente observar su comportamiento en la práctica. Usaremos los hiperparámetros que consideramos mejores en el anterior apartado y usaremos *accuracy* como medida de ajuste del modelo para determinar cuál es el mejor modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión - Decision Tree Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que el hiperparámetro que usaremos será *max_depth* = 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo de Árbol de decisión con el test de prueba es: 0.8164852255054432\n"
     ]
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=best_depth_tree, random_state=random_state)\n",
    "model_tree.fit(features_train, target_train)\n",
    "\n",
    "print(f\"La exactitud del modelo de Árbol de decisión con el test de prueba es: {model_tree.score(features_test, target_test)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bosque aleatorio - Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este modelo, los dos hiperparámetros que usaremos son *max_depth* = 10 y *n_estimators* = 40:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo de Bosque aleatorio con el test de prueba es: 0.8195956454121306\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(n_estimators=best_n_forest, max_depth=best_depth_forest, random_state=random_state)\n",
    "model_forest.fit(features_train, target_train)\n",
    "\n",
    "print(f\"La exactitud del modelo de Bosque aleatorio con el test de prueba es: {model_forest.score(features_test, target_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisión final y conclusiones del apartado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez probados nuestros modelos y dado que ambos superan el umbral mínimo requerido de exactitud, nos decantamos a utilizar el modelo de *Random Forest*. Aclaramos que la diferencia entre modelos resulta marginal utilizando *accuracy* como medida de ajuste y podríamos utilizar cualquiera de estos dos modelos. Para una mejor diferenciación y fundamento de elección podrían utilizarse otras métricas de evaluación de modelos, pero supondremos en esta ocasión que es suficiente, ya que el requerimiento fue específico con esta métrica y las capacidades de los modelos de *Random Forest* son en teoría más generalizables y superiores a los de *Decision Tree*\n",
    "\n",
    "Por tanto, el modelo escogido para usarse en el pronóstico y/o recomendación de clientes de la empresa Megaline será el de *Random Forest* (Bosque aleatorio), con los hiperparámetros utilizados líneas arriba.\n",
    "\n",
    "Una tarea adicional encargada es la de realizar una prueba de cordura de nuestro modelo final, esto con fines de comparación y tener en cuenta una referencia para determinar si este puntaje de exactitud es verdaderamente alto o no."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de cordura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check_0_pred = [0] * len(target_test)\n",
    "sanity_check_random_pred = np.random.choice([0,1], size=len(target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo de Bosque aleatorio con el test de prueba es: 0.8195956454121306\n",
      "La exactitud del test de cordura con 0 con el test de prueba es: 0.6967340590979783\n",
      "La exactitud del test de cordura aleatorio con el test de prueba es: 0.5489891135303266\n"
     ]
    }
   ],
   "source": [
    "print(f\"La exactitud del modelo de Bosque aleatorio con el test de prueba es: {model_forest.score(features_test, target_test)}\")\n",
    "\n",
    "print(f\"La exactitud del test de cordura con 0 con el test de prueba es: {accuracy_score(target_test, sanity_check_0_pred)}\")\n",
    "\n",
    "print(f\"La exactitud del test de cordura aleatorio con el test de prueba es: {accuracy_score(target_test, sanity_check_random_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
